{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import avg, col, min, max, sum, udf, count, countDistinct,\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import MinMaxScaler, VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark on Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the small dataset in json format\n",
    "sparkify_data = 'mini_sparkify_event_data.json'\n",
    "df = spark.read.json(sparkify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "df = df.dropna(how = 'any', subset = ['registration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Once you've familiarized yourself with the data, build out the features you find promising to train your model on. To work with the full dataset, you can follow the following steps.\n",
    "- Write a script to extract the necessary features from the smaller subset of data\n",
    "- Ensure that your script is scalable, using the best practices discussed in Lesson 3\n",
    "- Try your script on the full data set, debugging your script if necessary\n",
    "\n",
    "If you are working in the classroom workspace, you can just extract features based on the small subset of data contained here. Be sure to transfer over this work to the larger dataset when you work on your Spark cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features from `page`\n",
    "we have seen that the following page labels are very different in churn/unchurn groups and at the same time there are relatively a large percentage of these labels:\n",
    "Downgrade, Thumbs Down, Thumbs Up, Home, Add to Playlist, Add Friend, NextSong. We one hot encode these columns and then get the sum as feature in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns to take the pages names\n",
    "# this is one hot encoding\n",
    "features_page = ['Downgrade', 'Thumbs Down',' Thumbs Up', 'Home', \n",
    "                  'Add to Playlist',' Add Friend', 'NextSong']\n",
    "for feat in features_page:\n",
    "    df = df.withColumn(feat.replace(' ',''), (df.page == feat).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum up the counts for every page name\n",
    "df_page = df.groupBy('userId') \\\n",
    "          .agg(sum('Downgrade'),\n",
    "               sum('ThumbsDown'),\n",
    "               sum('ThumbsUp'),\n",
    "               sum('Home'),\n",
    "               sum('AddtoPlaylist'),\n",
    "               sum('AddFriend'),\n",
    "               sum('NextSong'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_page.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features from `level`\n",
    "The churn rate in free and paid groups are different by about 8%, we can use this one as our feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('hasPaid',(df.level == 'paid').cast(IntegerType()))\n",
    "df_level = df.groupBy('userId') \\\n",
    "             .agg(max('haspaid')) \\\n",
    "             .withColumnRenamed('max(haspaid)','hasPaid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_level.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features from `gender`\n",
    "The churn rate in free and paid groups are different by about 8%, we can use this one as our feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('isman',(df.gender == 'M').cast(IntegerType()))\n",
    "df_gender = df.groupBy('userId') \\\n",
    "              .agg(max('isman')) \\\n",
    "              .withColumnRenamed('max(isman)','isMale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features from `registration`\n",
    "New users tend to churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2day = udf(lambda x: x/(1000*3600*24))\n",
    "\n",
    "df_reg = df.groupBy('userId','registration') \\\n",
    "            .agg(max('ts')) \\\n",
    "            .withColumn('sinceRegDays',ms2day(col('max(ts)')-col('registration')).cast(FloatType())) \\\n",
    "            .select('userId','sinceRegDays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features from `sessionId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ses = df.groupBy('userId') \\\n",
    "           .agg(countDistinct('sessionId')) \\\n",
    "           .withColumnRenamed('count(DISTINCT sessionId)','numSessions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features from `ts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = df.groupBy('userId') \\\n",
    "          .agg(max('ts'),min('ts')) \\\n",
    "          .withColumn('activeDays', ms2day(col('max(ts)')-col('min(ts)')).cast(FloatType())) \\\n",
    "          .select('userId','activeDays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for modeling\n",
    "Some of the above features extracted can be divided by the activeDays column to get action frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define churn\n",
    "# just to repeat what was done in the first notebook\n",
    "user_window = Window.partitionBy('userId')\n",
    "function = udf(lambda hascancelled : int(hascancelled=='Cancellation Confirmation'), IntegerType())\n",
    "df = df.withColumn('reachedcancel',function(col('page'))) \\\n",
    "    .withColumn('Churn',Fsum('reachedcancel').over(user_window))\n",
    "\n",
    "# join all these dataframes on userId\n",
    "df_ml = df.select('userId','Churn').dropDuplicates()\n",
    "df_ml = df_ml.join(df_page,on='userId',how='inner') \\\n",
    "             .join(df_level,on='userId',how='inner') \\\n",
    "             .join(df_gender,on='userId',how='inner') \\\n",
    "             .join(df_reg,on='userId',how='inner') \\\n",
    "             .join(df_ses,on='userId',how='inner') \\\n",
    "             .join(df_ts,on='userId',how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is nice to try daily number of NextSong, but it is not that meaningful to say number of daily actions if the number is too small(<<1). So I keep the rest as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column DailyNumSongs\n",
    "df_ml = df_ml.withColumn('DailyNumSongs', col('sum(NextSong)')/col('activeDays'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change names of columns\n",
    "# change churn to label\n",
    "df_ml = df_ml.withColumnRenamed('sum(Downgrade)','Downgrade') \\\n",
    "             .withColumnRenamed('sum(ThumbsDown)','ThumbsDown') \\\n",
    "             .withColumnRenamed('sum(ThumbsUp)','ThumbsUp') \\\n",
    "             .withColumnRenamed('sum(Home)','Home') \\\n",
    "             .withColumnRenamed('sum(AddtoPlaylist)','AddtoPlaylist') \\\n",
    "             .withColumnRenamed('sum(AddFriend)','AddFriend') \\\n",
    "             .withColumnRenamed('sum(NextSong)','NextSong') \\\n",
    "             .withColumnRenamed('Churn','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ml.show(1,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Split the full dataset into train, test, and validation sets. Test out several of the machine learning methods you learned. Evaluate the accuracy of the various models, tuning parameters as necessary. Determine your winning model based on test accuracy and report results on the validation set. Since the churned users are a fairly small subset, I suggest using F1 score as the metric to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender and level can also be made numeric by stringindexers\n",
    "# and then use a pipeline to put together the indexers and assembler\n",
    "# but it seems easier to get them ready before this step\n",
    "# assemble the features\n",
    "assembler = VectorAssembler(inputCols=['Downgrade', \n",
    "                                       'ThumbsDown',\n",
    "                                       'ThumbsUp',\n",
    "                                       'Home',\n",
    "                                       'AddtoPlaylist',\n",
    "                                       'AddFriend',\n",
    "                                       'DailyNumSongs', \n",
    "                                       'hasPaid',\n",
    "                                       'isMale',\n",
    "                                       'sinceRegDays',\n",
    "                                       'numSessions',\n",
    "                                       'activeDays'],\n",
    "                            outputCol='features')\n",
    "data = assembler.transform(df_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax scale features\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(data)\n",
    "data = scalerModel.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train, test = data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "classifier_lr = LogisticRegression(labelCol=\"label\",\n",
    "                                featuresCol=\"scaledFeatures\",\n",
    "                                maxIter=5, \n",
    "                                regParam=0.0, \n",
    "                                elasticNetParam=0)\n",
    "classifierModel_lr = classifier_lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "preds_lr = classifierModel_lr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "def evalModel(preds):\n",
    "    accEval = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "    f1sEval = MulticlassClassificationEvaluator(metricName='f1')\n",
    "    \n",
    "    acc = accEval.evaluate(preds.select(col('label'), col('prediction')))\n",
    "    f1s = f1sEval.evaluate(preds.select(col('label'), col('prediction')))\n",
    "    \n",
    "    print('accuracy:', acc)\n",
    "    print('f1 score:', f1s)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7941176470588235\n",
      "f1 score: 0.7262656475019387\n"
     ]
    }
   ],
   "source": [
    "evalModel(preds_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8823529411764706\n",
      "f1 score: 0.8669467787114846\n"
     ]
    }
   ],
   "source": [
    "# repeat the above steps using random forest classifier\n",
    "classifier_rf = RandomForestClassifier(labelCol=\"label\",\n",
    "                                    featuresCol=\"scaledFeatures\",\n",
    "                                    seed=42)\n",
    "classifierModel_rf = classifier_rf.fit(train)\n",
    "preds_rf = classifierModel_rf.transform(test)\n",
    "evalModel(preds_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8529411764705882\n",
      "f1 score: 0.8558246828143022\n"
     ]
    }
   ],
   "source": [
    "# repeat the above steps using gradient boost tree classifier\n",
    "classifier_gbt = GBTClassifier(labelCol=\"label\",\n",
    "                           featuresCol=\"scaledFeatures\",\n",
    "                           seed=42)\n",
    "classifierModel_gbt = classifier_gbt.fit(train)\n",
    "preds_gbt = classifierModel_gbt.transform(test)\n",
    "evalModel(preds_gbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the model\n",
    "The randome forest model is the best, so let's tune this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier??\n",
    "# MulticlassClassificationEvaluator??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the model\n",
    "rf = RandomForestClassifier(labelCol=\"label\",\n",
    "                            featuresCol=\"scaledFeatures\",\n",
    "                            seed=42)\n",
    "# build params\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.minInstancesPerNode,[1, 3, 5]) \\\n",
    "    .addGrid(rf.maxDepth,[2, 4, 8]) \\\n",
    "    .build()\n",
    "\n",
    "# initiate crossvalidator\n",
    "crossval_rf = CrossValidator(estimator=rf,\n",
    "                             estimatorParamMaps=paramGrid,\n",
    "                             evaluator=MulticlassClassificationEvaluator(),\n",
    "                             numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7421574948767932,\n",
       " 0.8105860273482082,\n",
       " 0.8036588602213759,\n",
       " 0.7421574948767932,\n",
       " 0.8117395770053698,\n",
       " 0.8130240381339346,\n",
       " 0.7421574948767932,\n",
       " 0.788348089492855,\n",
       " 0.8060755307071097]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel_rf = crossval_rf.fit(train)\n",
    "cvModel_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=RandomForestClassifier_419186432dbe) with 20 trees"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel_rf.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is funny that we had actually a better model before the tuning part. Anyway, we now know that the maxDepth=5 is actually the best parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this project, I have gone through 6 main steps, every one is very important:\n",
    "* **data wrangling**  \n",
    "    In this step, it was important to understand that the missing values are due to users who are not logged in.\n",
    "* **define the goal**  \n",
    "    In this step, I define the goal as predicting the churn users.\n",
    "* **EDA**  \n",
    "    In this step, I searched for all the promising features that are related to churn by comparing different metrics for churn users and unchurn users.\n",
    "* **feature engineering**  \n",
    "    In this step, I extracted the good features to predict churn users.\n",
    "* **fitting models**  \n",
    "    In this step, I tried 3 different models, namely Logistic Regression, Random Forest, and Gradient Boost Tree. I found out that Random Forest performs the best.\n",
    "* **tuning model**  \n",
    "    In this step, I have tuned the best model, Random Forest, using a parameter grid of minInstancesPerNode and maxDepth.\n",
    "\n",
    "The challenge of project is that we need to use spark to analyze data, since the dataset is too large that a single computer is not capable of manipulating it. In this project, however, due to very limited time, I have only tried to complete this procedure on a small subset of the full dataset. Hope that I will have chance to run my script on large clusters in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Steps\n",
    "Clean up your code, adding comments and renaming variables to make the code easier to read and maintain. Refer to the Spark Project Overview page and Data Scientist Capstone Project Rubric to make sure you are including all components of the capstone project and meet all expectations. Remember, this includes thorough documentation in a README file in a Github repository, as well as a web app or blog post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
